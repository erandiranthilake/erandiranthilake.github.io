---
layout : "post"
title : "Final Project: Messaging Spam Detector"
author : "Erandi Ranthilake"
hasGit : true
gitProject : "https://github.com/erandiranthilake/spamDetector"
hasLink : true
link : "https://erandiranthilake.github.io/"
linkTitle: "Home Page Link: https://erandiranthilake.github.io/"

---
<h2>Contribution :</h2>
<h3>Technical Documentation on Naive Bayes Classifier and Text Optimization<br>
Improved Naive Bayes Classifier with Text optimazation</h3>
<hr>

<a href="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/Project_proposal.pdf">Project Proposal</a><br>
<a href="https://www.kaggle.com/erandiranthilake/spam-detector-naive-bayes">Link to Kaggle notebook - Spam Detector</a><br>
<a href="https://youtu.be/ZMgtnWgzte4">YouTube Video Link - Spam Detector</a><br>

<hr>
<div style="text-align: justify"> 
With the expansion of the technology around the globe, digital messaging has become an important part of everyday life. These messaging systems can include SMS, Email, IM in various apps etc. While many uses these messages to communicate in personal or professional setup, some use these systems as information sources. For this reason, these platforms are targeted by many groups to share information and advertise products or services. Among these groups can exist some individuals that may misuse the
system.<br><br>
A spam is any unwanted or unsolicited message sent to your device, often for commercial purposes. But it could take other form such as, a link to a number to call or text, a link to a website for more information. It is estimated that in the United States, every year almost 4.5 billion spam texts end up in inboxes.<br><br>

<h3>Why someone need an application to detect spam messages?</h3>
As discussed above, digital messaging systems are one of the most effective ways to reach a larger population. This fact can be used by individuals who are interested in <b>distributing false information</b> among groups. This was widely seen during election campaigns and any kind of a crisis that could potentially disturb the peace and security in communities. Some hackers use digital messaging systems to <b>obtain personal information</b> about individual. They may ask for information such as name, address, or
worse, bank details and other sensitive information in order to win a prize. This can lead to <b>identity theft</b> and fraudulent transaction of money from bank accounts. <b>SMS phishing</b> is also a known method of obtaining personal information about individuals. <b>Advertising products or services that are fraudulent</b> is also seen in many cases, that could potentially lead people to send money to hackers. The consequences of such attacks can be destructive, where victims can lose money, expose personal and financial information and jeopardize their business reputation.<br><br>

<h3>What features are included in this app?</h3>
1. Detect spam messages with an accuracy of > 90%.<br>
2. Flag the spam messages when they reach inbox<br>
3. Check if a given text message is a Spam or not<br>
4. Gather data and improve the model to detect spam messages with greater accuracy<br>
<br><br>


<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/spam_ss.png" alt="Spam Detector"><br>
<i> Spam Detector Application User Interface Sketches</i>
<br><br>

<h3>Methodology and Dataset</h3>
In order to develop the application, we will be using a data model designed using Naïve Bayes classifier. The model will be optimized using techniques such as Smoothing and Text optimization methods. We will be using a dataset from Kaggle.com, SMS spam collection dataset<br>
<a href="https://www.kaggle.com/uciml/sms-spam-collection-dataset">Link to Kaggle dataset - SMS Spam collection dataset</a><br>

<h2>Naive Bayes Classification</h2>
Naïve Bayes classification is a method used to calculate the probability of a outcome, given certain features, which can be depicted as P(L|features).  This is a very strong data minning technique for predictive models. The base theory behind this classifier is the Bayes's Theorem, which describes the relationship of conditional probabilities of statistical computations in the following equation.<br><br>

<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/bayes_equation.JPG" alt="bayes_equation"><br>
<i>Bayes Equation</i>
<br><br>

<b>Improving the Model using Smoothing</b><br><br>
If a given feature and the outcome never occur together in the training dataset, the probability calculation for all the features will be zero. This will lead to an incorrect prediction as the other features that occurred with the outcome could actually have an impact on the predict. In order to prevent this we introduce Smoothing. <br><br>

In smoothing when we calculate the conditional probability, we add 1 to the numerator and number of unique occurrences of the features to the denominator. If we are developing a binary classification model we can simply add 2 to the denominator.<br><br>

Following is theconditional probability calculation implementing smoothing<br><br>
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/cond_prob_smoothing.JPG" alt="cond_prob_smoothing.JPG"><br>
<i> Modified conditional probability calculation to implement smoothing</i>
<br><br>

<h2>Text Optimization</h2>
The challenge of analyzing text is the ambiguity of languages. Given a certain text, a machine can generate several valid interpretations. Therefore, in any kind of text analysis process, it is paramount to pre-process the data. It is also important to ensure such methods are not overly done, as this could cause a lost of quality in the data that may be important for the analysis. In this project as part of the pre-processing data we will conduct following techniques to improve the quality of the textual data and compare the effect of text optimization.<br><br>

1. Remove stop words – stop words are a group of words that are commonly used in any language.<br>
2. Stemming - Stemming is a process of reducing inflected words to their root form.<br><br>

These techniques can be simply applied by using python libraries such as Natural Language ToolKit (NLTK)<br><br>

<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/nltk.JPG" alt="NLTK"><br>
<i> Natural Language ToolKit (NLTK)</i>
<br><br>

<h2>Methodology</h2>

The data will be loaded into a data frame with the colums of outcome, spam or ham, and the text.<br><br>

<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/spam_data.JPG" alt="load Data"><br>
<i> Loading Data</i>
<br><br>

Data will be divided into a several different sets, which include spam texts as well as non-spam text.<br><br>

<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/spam_datasplit.JPG" alt="data split"><br>
<i> Data divided into subsets</i>
<br><br>

Each dataset is processed to generate training and test data. Training data will be used to generate tonal vocabularies, text optimized and non-optimized. Then using the test data from the same subset accuracy of the predictions are evaluated.<br><br>
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/spam_model.JPG" alt="Process data"><br>
<i> Processing datasets</i>
<br><br>

<h3>Results</h3>

Average accuracy of predicting the if a text is a spam or not when the model is not optimized is <b>0.5307</b> where as in the optimized model the the prediction accuracy is 0.9227.<br><br>

<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/spam_accuracy.JPG" alt="Numerical Accuracy"><br>
<i> Prediction accuracy for each data set and Average</i>
<br><br>

<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/bar_chart.JPG" alt="bar chart"><br>
<i> Optimized Vs Not-Optimized model outputs</i>
<br><br>

<h3>Conclusion</h3>

It is evident that when the classifier optimization techniques such as smoothing combined with text optimization techniques such as removing stop words and stemming of the word, can result in a much higher accuracy for predicting whether a text is a spam. Therefore, these techniques are highly recommended to be applied in ML models that perform textual data analysis.
<br><br>


<h3>Challenges </h3>
A challenge faced was the calculation duration. Since the classification model includes many probability calculations, the calcualtion time is considerably large. Therefore smaller datasets are processed.


<hr>

<h2>References</h2> 
1. <a href="https://www.kaggle.com/alexisbcook/titanic-tutorial">Titanic Tutorial</a><br>
2. <a href="https://www.analyticsvidhya.com/blog/2020/05/decision-tree-vs-random-forest-algorithm/">Decision Tree Vs Random Forest</a><br>
3. <a href="https://towardsdatascience.com/from-a-single-decision-tree-to-a-random-forest-b9523be65147">Random Forest</a><br>
4. <a href="https://www.youtube.com/watch?v=nxFG5xdpDto&ab_channel=KrishNaik">Random Forest Development</a><br>
5. <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">Neural Networks</a><br><br>

</div>

