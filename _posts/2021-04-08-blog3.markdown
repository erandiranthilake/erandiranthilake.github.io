---
layout : "post"
title : "Overfitting of Model and Regularization"
author : "Erandi Ranthilake"
hasGit : true
gitProject : "https://github.com/erandiranthilake/Assigment_02"
hasLink : true
link : "https://erandiranthilake.github.io/"
linkTitle: "Home Page Link: https://erandiranthilake.github.io/"

---
<h2>Contribution :</h2>
<h3>Technical Documentation for Overfitting of Models and Different resolution methods<br>
Implementation and comparison of models based on Root Mean Squre Error and R2 Score </h3>
<hr>

<a href="https://github.com/erandiranthilake/Assigment_02">Link to Jupyter Notebook</a><br>
<hr>

<div style="text-align: justify"> 
<h2>Overfitting a model</h2>
Overfitting a model can be simply explainded as modelling a function too closely fit to a given set of data points. As the data used to train the models have a some degree of error in them, when overfitting occurs this inaccurate data infect the model leading to a substantial error. This reduces the predictive power of the model.<br><br>

<b>Reasons for Overfitting</b> are mainly using limited training data set and using complex algorythms or training techniques. You can <b>identify overfitting</b> when you see a small training error and a large testing error<br>


<h2>Demonstrating overfitting</h2>
In the developed notebook, smaller training sample is generated using y = sin(2*pi*X) + 0.1 * N<br>
Using root mean squre error, polynomial regression for different order (0, 1, 3, 9) is assessed<br><br>

<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/graph_degree1.JPG" alt="polynomial degree"><br>
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/graph_degree2.JPG" alt="polynomial degree"><br>
<i>Source: Data points plotted at different degrees</i>
<br><br>


<b>Input Layer:</b> Some networks consis of an input layer which load teh images and uses a resulting output to load to convolutional layer. Various operations can take place in this layer as preparations for the next layers, such as, mean-substraction and feature-scaling.
<br>
<b>Convolutional layer:</b>This is the main feature extraction or learning layer in the network. Convolutional layer convolves the input with a set of filters which produces a feature map in the output.
<br>
<b>Pooling layer:</b>This layer is responsible for reducing the spatial dimension of teh input. There is a Pooling layer after each convolutional layer.
<br>
<b>Fully connected layer:</b>This layer consider the input as a single vector and produce a single vector as the output. With in the same layer an activation function such as 'softmax activation' can be used to categorize teh final output.
<br><br>

<h2>What is the best model for image classification?</h2>
Image classification, object detection and other important areas of computer vision have numerous applications in different fields such as security, medical, surveillance, etc. Although Convolutional neural networks have been identified as one of the best methodologies to develop models for image classification, there are number of parameters that can account for the efficiency and accuracy of these models. Ongoing research have identified that <b>deep networks</b> can improve accuracy of the models, where as <b>shallow networks</b> are more efficient. Nevertheless, possibility of improving CNN models by fine-tuning different parameters is an area researched extensively.
<br><br>
The effort of this article is to identify some of these parameters that can affect the accuracy of models and try to improve an existing base model using those parameters.
<br><br>

<h3>Image Classification using CIFAR 10 and CNN model : <b>Base Model</b></h3>
A base CNN model is developed using 'Keras' Python library.<br>
Base model consists of three convolutional layers with 4, 8, 16 neurons in each layer. A filter size of 7 * 7 is used with padding 'same'.
<br><br>
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/model_code.JPG" alt="CNN Model codebase"><br>
<i>CNN model (Source: Tensorflow Tutorial)</i>
<br><br>
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/model_summary.JPG" alt="CNN Model summary"><br>
<i>Model Summary</i>
<br><br>
Model is trained using 'Adam' Optimizer and 'sparse_categorical_crossentropy' as the loss function.
<br><br>
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/model_train.JPG" alt="CNN Model codebase"><br>
<i>Training model</i>
<br><br>

<h3>Comparison of Models based on Neuron Count</h3>
Following different models are developed to compare the base accuracies against different neuron counts.
<br><br>
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/neuron_count_box.JPG" alt="neuron_count_table"><br>
<i>Models and neuron counts in each layer</i>
<br><br>
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/neuron_count_chart.JPG" alt="neuron_count_chart"><br>
<i>Average Accuracy of each model</i>
<br><br>
Based on the above findings we can conclude that performance of the model improves with increasing number of neurons in each layer.
<br><br>

<h3>Comparison of Models based on Filter size</h3>
Following different models are developed to compare the base accuracies against different filter sizes.
<br><br>
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/filter_size_table.JPG" alt="filter_size_table"><br>
<i>Models and Filter sizes</i>
<br><br>
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/filter_size_chart.JPG" alt="filter_size_chart"><br>
<i>Average Accuracy of each model</i>
<br><br>
Based on the above findings we can conclude that performance of the model improves with decreasing filter sizes.
<br><br>

<h3>Comparison of Models based on Number of Layers</h3>
Following different models are developed to compare the base accuracies against different number of layers.
<br><br>
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/layers_table.JPG" alt="filter_size_table"><br>
<i>Models and Number of Layers</i>
<br><br>
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/layers_chart.JPG" alt="filter_size_chart"><br>
<i>Average Accuracy of each model</i>
<br><br>
Based on the above findings we can conclude that performance of the model decreases when the number of layers are considerably low or high. Performance of the model was high when the number of layers is 4.
<br><br>

<h2>Conclusion</h2>
Considering the parameters tested above we can conclude that the performance of a Convolutional Neural Network model can be improved by increasing the neuron count, decreasing the filter size and fine-tuning the number of filters accordingly.
<br><br>
Following Models are developed to test these findings and improve the performance of the base model used.
<br><br>

<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/final_table.JPG" alt="filter_size_table"><br>
<i>Base model and enhanced model to improve performance</i>
<br><br>
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/final_chart.JPG" alt="filter_size_chart"><br>
<i>Average Accuracy of each model</i>
<br><br>

<h2>Challenges</h2>
Main challenge faced during the process was limitation of machine power to process increased number of layers and larger data sets. As a measure to overcome these issues, at times the models were run through limited data sets. Possible improvement concerning machine power is using GPU.
<br><br>

<hr>

<h2>References</h2>Â 
1. <a href="https://www.tensorflow.org/tutorials/images/cnn">TensorFlow Tutorial</a><br>
2. <a href="https://www.altexsoft.com/blog/image-recognition-neural-networks-use-cases/">Image Recognition with Deep Neural Networks and its Use Cases</a><br>
3. <a href="https://www.researchgate.net/profile/Wu-Xiongwei/publication/335135074_Recent_Advances_in_Deep_Learning_for_Object_Detection/links/5e27f1c8a6fdcc70a140e4ac/Recent-Advances-in-Deep-Learning-for-Object-Detection.pdf">Recent Advances in Deep Learning for Object Detection</a><br>
4. <a href="https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks">ML Practicum: Image Classification</a><br>
<br><br>

</div>
