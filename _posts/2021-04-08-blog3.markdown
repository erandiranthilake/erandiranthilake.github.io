---
layout : "post"
title : "Overfitting of Model and Regularization"
author : "Erandi Ranthilake"
hasGit : true
gitProject : "https://github.com/erandiranthilake/Assigment_02"
hasLink : true
link : "https://erandiranthilake.github.io/"
linkTitle: "Home Page Link: https://erandiranthilake.github.io/"

---
<h2>Contribution :</h2>
<h3>Technical Documentation for Overfitting of Models<br>
Implementation and comparison of models based on Root Mean Squre Error and R2 Score </h3>
<hr>

<a href="https://github.com/erandiranthilake/Assigment_02">Link to Jupyter Notebook</a><br>
<hr>

<div style="text-align: justify"> 
<h2>Overfitting a model</h2>
Overfitting a model can be simply explainded as modelling a function too closely fit to a given set of data points. As the data used to train the models have a some degree of error in them, when overfitting occurs this inaccurate data infect the model leading to a substantial error. This reduces the predictive power of the model.<br><br>

<b>Reasons for Overfitting</b> are mainly using limited training data set and using complex algorythms or training techniques. We can <b>identify overfitting</b> when there is a  smaller training error and a larger testing error<br>


<h2>Demonstrating overfitting</h2>
In the developed notebook, smaller training sample is generated using y = sin(2*pi*X) + 0.1 * N<br>
Using root mean squre error, polynomial regression for different order (0, 1, 3, 9) is assessed<br><br>

<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/code_degree.JPG" alt="code degree"><br>
<i>Code base for models</i>
<br><br>

<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/graph_degree1.JPG" alt="polynomial degree"><br>
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/graph_degree3.JPG" alt="polynomial degree"><br>
<i>Data points plotted at different degrees</i>
<br><br>

Overfitting can be seen when the degree is 9. In order to numberically demonstrate overfitting we can calculate the training error and testing error in increasing degrees.<br><br>

<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/code_error.JPG" alt="code error"><br>
<i>Code base for calculating error at different degrees</i>
<br><br>

<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/graph_error.JPG" alt="error"><br>
<i>Training Error vs Testing Error</i>
<br><br>
<br>


<h2>How to prevent overfitting?</h2>
There are several identified ways to prevent overfitting. In this post we will dicuss preventing over fitting by increasing the amount of data points and through regularization
<br><br>

<h3>Increasing the number of Data points</h3>
As oppose to using 10 data points to train, we will use 100 Data points and a 9th order model to compare the results.
<br><br>

<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/graph_data100.JPG" alt="increased data">
<i>Number of data point vs fitting of the model</i>
<br><br>

We can clearely observe that the overfitting no longer exist when the number of data points is increased.
<br><br>

<h3>Regularization</h3>
We will be using a predefined regularization calculation to regularize the model and train the model. THe behaviour of the model is observed with changing alpha values.
<br><br>

<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/regu_1.JPG" alt="regularization 1">
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/regu_2.JPG" alt="regularization 2">
<i>Regularization: Fitting of the model with changing alpha values</i>
<br><br>

To analyse these data more in depth, we can see how Root mean squre error changes with different alpha values. In the folliwing figures you can see how the training and test error changes with Lasso Regularization and Ridge Regularization, two commonly used regularization techniques for regression models.
<br><br>
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/lasso_regu.JPG" alt="Lasso regularization">
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/ridge_regu.JPG" alt="Ridge regularization">
<br><br>

<h3>Comparison of Models based on Neuron Count</h3>
Following different models are developed to compare the base accuracies against different neuron counts.
<br><br>
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/neuron_count_box.JPG" alt="neuron_count_table"><br>
<i>Models and neuron counts in each layer</i>
<br><br>
<img src="https://raw.githubusercontent.com/erandiranthilake/erandiranthilake.github.io/gh-pages/images/neuron_count_chart.JPG" alt="neuron_count_chart"><br>
<i>Average Accuracy of each model</i>
<br><br>
Based on the above findings we can conclude that performance of the model improves with increasing number of neurons in each layer.
<br><br>

<h2>Challenges</h2>
Main challenge faced during the process was limitation of machine power to process increased number of layers and larger data sets. As a measure to overcome these issues, at times the models were run through limited data sets. Possible improvement concerning machine power is using GPU.
<br><br>

<hr>

<h2>References</h2>Â 
1. <a href="https://www.tensorflow.org/tutorials/images/cnn">TensorFlow Tutorial</a><br>
2. <a href="https://www.altexsoft.com/blog/image-recognition-neural-networks-use-cases/">Image Recognition with Deep Neural Networks and its Use Cases</a><br>
3. <a href="https://www.researchgate.net/profile/Wu-Xiongwei/publication/335135074_Recent_Advances_in_Deep_Learning_for_Object_Detection/links/5e27f1c8a6fdcc70a140e4ac/Recent-Advances-in-Deep-Learning-for-Object-Detection.pdf">Recent Advances in Deep Learning for Object Detection</a><br>
4. <a href="https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks">ML Practicum: Image Classification</a><br>
<br><br>

</div>
